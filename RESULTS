1737 articles
Label: day_after_label
0.85 split (randomized)
C = 1
beta = 1

10 Iterations of Test errors: 
	[0.4695, 0.4389, 0.4733, 0.4160, 0.4695, 0.4427, 0.4008, 0.4466, 0.4084, 0.4427]

Taking away words with high occurances.
 0.4313    0.4351    0.4466    0.3931    0.4313    0.4427    0.4656    0.4580    0.4580    0.4160


 plot1:
 Average training and test error iterated over beta = [0.2:0.2:1, 2:2:20];
 Note: Using stricly less-than. 

 plot2:
 Average training and test error iterated over small betas: betas=[0.001:0.001:0.01];

 plot3: 
 Using errors = sum(agreement < 0) + .5*sum(agreement == 0)... 
 Large Betas
 Average training and test error iterated over beta = [0.2:0.2:1, 2:2:20];

 plot4:
 Using errors = sum(agreement < 0) + .5*sum(agreement == 0)... 
 small betas: Average training and test error iterated over small betas: betas=[0.001:0.001:0.01];

 ... with beta = 0.008 being the best (error = 0.438)
	 avg_test_errors =

	    0.4313    0.4397    0.4496    0.4405    0.4504    0.4366    0.4481    0.4328    0.4573    0.4405


	avg_train_errors =

	    0.4373    0.4064    0.3737    0.3395    0.3285    0.3035    0.2838    0.2689    0.2510    0.2344


############## Regreassion ############

plot5:
Using Linear Regressing....
Small betas: [0.001:0.001:0.01];
C = 1. 
	avg_test_errors =

	    0.4298    0.4489    0.4580    0.4603    0.4885    0.4611    0.4458    0.4779    0.4733    0.4802


	avg_train_errors =

	    0.3073    0.2431    0.2161    0.1936    0.1742    0.1600    0.1406    0.1341    0.1192    0.1121

plot6:
Using Linear Regressing....
Small betas: [0.01:0.01:0.1];
C = 1. 

	avg_test_errors =

	    0.4702    0.4840    0.4641    0.4412    0.4870    0.4443    0.4374    0.4466    0.4534    0.4695


	avg_train_errors =

	    0.1139    0.0759    0.0609    0.0504    0.0423    0.0393    0.0376    0.0348    0.0320    0.0297

plot7:
Using MATLAB's SVMtrain and the full feature vector....
3 iterations per combination of parameters
C = 1, beta = [0.001:0.001:0.01];

plot8:
Testing SVM using RBkernel, C = 1, beta = [0.001:0.001:0.1] (100beta points) 
Error is the average error from LOOCV. The graph shows a convergence to 0.4347 as beta goes to infty
The first beta value to acieve this value is beta = 3

plot9:
Horizontal Axis: log_10(x)
This plot shows that any C>=1 will give a good result. 

############ Label Comparisons #############
Using the best combination of parameters that we've got: C = 1, beta = 0.008
We run 10 iterations for each label and take the average error:

After-Day Label: 0.4540
Next-Day Label: 0.4740
End-to-End-Day label: 0.4847

We now update the labels to show percent change. 
Use the same combination of parameters: C = 1, beta = 0.008

After-Day Label: 0.4458
Next-Day Label: 0.4777
End-to-End-Day label: 0.4885

---> Conclude: not much change. 


########## TODO ###########
script3 # Find the best Beta and C combination using ALL DATA. 
		# Beta = [0.001:0.001:0.01 0.015:0.005:0.05 0.6:0.1:1]
		# C = [0.1:0.1:1 2:1:10]









